# 2章

## 2-2

ViTは大きく分けて以下の3つの部分で構成されている。

* InputLayer
  * 入力画像をパッチに分割
  * クラストークンと各パッチに対応するベクトルを出力
* Encoder
  * 入力として、クラストークンと各パッチに対応したベクトルを受け取る
  * 出力はクラストークン
  * 複数のEncoder blockからなる。
    * 各Encoder blockはSelf-AttentionとMLPからなる。
* MLP Head

## 2-3 InputLayer

パッチに分割
埋め込み
クラストークン
位置埋め込み

### 2-3-1 パッチに分割

ViTはTransformerをベース（厳密にいえば、TransformerのEncoderをベース）にしているため入力はベクトル
Transformerは文章を単語に分割しそれをベクトルに変換する。
じゃあ画像の場合は？
ViTは入力画像を**パッチ**に分割する。
例えば、画像を2x2のサイズで分割する。
しかし画像はカラー画像の場合、高さ×横×チャンネル数のテンソルでベクトルではない。
そこで各パッチを1次元のベクトルにする。これを実現するのがflatten処理。
この段階で各入力ベクトルはRGBの値を0～255の範囲であらわす整数値（正規化されていれば実数）

### 2-3-2 パッチの埋め込み

埋め込み(Embedding)とは、画像や動画、テキストなどのデータをベクトルで表現すること。
ここでは元バッチのベクトルよりも「より良いベクトル」を得ることが目的。
ベクトル化の方法にOne-hotベクトル化というものがある。ベクトルの各要素を0か1で表現する。
より良いベクトルとは各バッチ間の関連性や類似性を考慮されていることを指す。
しかし、これを人の手で行うには複雑すぎるため、線形層をはじめとしたニューラルネットワークに任せる。
ここで「より良いベクトル」より具体的にすると、ニューラルネットワークの学習によって得られる最終的な損失を小さくするようなベクトルになる。
そして、このようなより良いベクトルを獲得するために用いる線形層などを**埋め込み層**と呼ぶ。

NOTE: ニューラルネットワークによってクロスエントロピー損失などを小さくするように学習されると書いてある。
この場合、教師データは何になる？
-> 自分で教師データを作ってそれに対して学習？

### 2-3-3 クラストークン

クラストークン＝**画像全体の情報を凝縮したベクトル**
後述するself attentionにより画像全体の情報が凝縮される。
クラストークンはパッチの埋め込みと同じ長さのベクトル。
学習可能なパラメータ
標準正規分布に従った乱数をクラストークンの初期値とする。
全てのパッチ埋め込みの先頭にクラストークンを新たに結合してEncoderへの入力にする。

NOTE: クラストークンは何を基準に学習される？
NOTE: クラストークンだけで検出できるの？
→今回は1枚の画像に1つの物体があり、それを検出するタスクのためクラストークンだけでいい？

### 2-3-4 位置埋め込み

位置埋め込み(Position Embedding)
この処理はSelf-Attentionだけではパッチの位置情報を学ぶことができないという弱点を補間する。
位置情報とはパッチが画像内の何処に位置するかを示す情報。

クラストークン同様学習可能なパラメータ

## 2-4 Self-Attention

EncoderはInputLayerで獲得したベクトルを入力にとり、クラストークンを出力する
EncoderにはSelf-Attention（自己注意）という機構が用いられる。

### 2-4-1 Self-Attentionのキモチ

「自分に似た人たちを集めてより良い自分になる。」というイメージ
→自分＝パッチ

各パッチの情報の抽出
あるパッチとの類似度の測定
類似度に基づいたがったパッチ同士の合体

情報の抽出は埋め込みによって実現する
類似度の測定は、埋め込みによって得られたベクトル同士の内積によって計算する。
合体は内積の値を係数にした加重和によって求める。

### 2-4-2 Self-Attentionの埋め込み

2-3-2項でもあったが、埋め込みを行うとベクトルをより良いベクトルに変換できる。
Self-Attentionでもこの操作を行う。
埋め込み層としては1層の線形層を用いる。
この時線形層を3つ用意して、それぞれの線形層で埋め込んだ後の各ベクトルをそれぞれクエリq(query), キーk(key), バリューv(value)と呼ぶ
この3つはそれぞれ異なる線形層を使って埋め込まれているため異なる値を取る。
そして、クエリ―とキーの内積を求め(次項)、バリューは加重和(2-4-4)に用いる。

このクエリ―、キー、バリューという表現は動画ストリーミングサイトにおける動画検索を考えるとわかりやすい。
クエリは検索ワード、キーは動画のタイトルや説明文、バリューは動画自体を指す。
動画を検索するとき、検索キーワードと動画のタイトルの一致度を見るはず。
Self-Attentionでも同様にクエリとキーの類似度を計算し、その類似度を元にバリューの加重和を行う。

### 2-4-3 Self-Attentionの内積

埋め込み層で算出したqとkの内積(行列積)を計算する。
この行列積によって得られた行列は**Attention Weight**と呼ばれる。
内積はベクトル同士の類似度を表している。
ベクトルは大きさと向きで構成される。
大きさと向きに近いものほど内積は大きくなる。
行列積を計算した後にsoftmax関数に渡すことで行方向の和を1にする。
この操作をすることで加重和の係数を得る。
加重和の係数がまとめられた行列は**Attention Weight**と呼ばれる。
Attention Weightの各要素はパッチのベクトルの内積なので、パッチ同士の行列が似ていると大きくなる。
